---
layout: post
title: 핸즈온_머신러닝(3)
subtitle : Chaper 03 - 분류
tags: [머신러닝]
author: sunsoo Kim
comments : False
---

# Chaper 03 - 분류

##  MNIST
* 고등학생과 미국 인구조사국 직원들이 손으로 쓴 70,000개의 작은 숫자 이미지를 모은 MNIST 데이터셋 사용 예정

* 각 이미지에는 어떤 숫자를 나타내는지 레이블 되어 있음
* 새로운 분류 알고리즘이 나올 때마다 MNIST 데이터셋에서 얼마나 잘 작동하는지 확인

- 머신러닝 분야의 "Hello world!!"


사이킷런에서 제공하는 데이터셋들은 일반적으로 비슷한 딕셔너리 구조
* 데이터셋을 자세한 설명하는 DESCR 키
* 행은 샘플, 열은 특성으로 구성된 배열을 가진 data 키
* 레이블 배열을 담은 target 키 


```python
from sklearn.datasets import fetch_openml
mnist = fetch_openml('mnist_784', version=1) # as_frame = True
mnist.keys()
```




    dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])



* data  - 이미지 숫자 데이터 (70000만개의 28*28 픽셀의 데이터)
* target - data에 대한 실제 숫자값  
* frame -  as_frame = True 설정시만 data,target이 합쳐진 프레임 
* categories - 범주형일경우 카테고리값 있음
* feature_names - 특성의 이름(28*28구조 -> 1px, 2px...)여기에선 의미없음
* target_names - 0 ~ 9 값
* DESCR - 상세 정보
* details - json형식의 메타데이터
* url - 데이터 링크 주소 


```python
mnist['details'] 
```




    {'id': '554',
     'name': 'mnist_784',
     'version': '1',
     'format': 'ARFF',
     'upload_date': '2014-09-29T03:28:38',
     'licence': 'Public',
     'url': 'https://www.openml.org/data/v1/download/52667/mnist_784.arff',
     'file_id': '52667',
     'default_target_attribute': 'class',
     'tag': ['AzurePilot',
      'OpenML-CC18',
      'OpenML100',
      'study_1',
      'study_123',
      'study_41',
      'study_99',
      'vision'],
     'visibility': 'public',
     'status': 'active',
     'processing_date': '2018-10-03 21:23:30',
     'md5_checksum': '0298d579eb1b86163de7723944c7e495'}




```python
X, y = mnist["data"], mnist["target"]
X.shape
```




    (70000, 784)



X의 데이터 
* 이미지 70000
* 784개의 특성

( 784개의 특성이 이유는 28*28픽셀 )


```python
# 타겟 갯수 확인
y.shape
```




    (70000,)




```python
#1번째 데이터
%matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt

some_digit = X[0] # 샘플의 특성 벡터 추출 
some_digit_image = some_digit.reshape(28, 28) # 28 * 28 배열로 바꾸기
plt.imshow(some_digit_image, cmap=mpl.cm.binary) 
# cmap='binary'는 흑백 반전 
# matplotlib의 imshow() 함수로 그리기
plt.axis("off")

plt.show()
```


![png](https://user-images.githubusercontent.com/45762604/85260426-9fb0f780-b4a5-11ea-8ded-d8002d1d36b9.png)



```python
# 70000번째 데이터
# some_digit = X[69999] # 샘플의 특성 벡터 추출 
# some_digit_image = some_digit.reshape(28, 28) # 28 * 28 배열로 바꾸기
# plt.imshow(some_digit_image, cmap=mpl.cm.binary) # matplotlib의 imshow() 함수로 그리기
# plt.axis("off")

# plt.show()
```


```python
# X의 data 와 y의 taget 값 확인
print(y[0])
# print(y[69999])
```

    5



```python
# 만약 레이블값이 문자열인 경우 -> 정수로 변환 
# y = '5'
y = y.astype(np.uint8)
y[0]
```




    5




```python
# 위에 샘플의 벡터 추출했던 모드 함수화
def plot_digit(data):
    image = data.reshape(28, 28)
    plt.imshow(image, cmap = mpl.cm.binary,
               interpolation="nearest")
    # interpolation="nearest" 주변의 값 이용 저장하는 방식
    
    plt.axis("off")

```


```python
# 숫자 출력을 위한 추가 함수
def plot_digits(instances, images_per_row=10, **options):
    size = 28
    images_per_row = min(len(instances), images_per_row)
    images = [instance.reshape(size,size) for instance in instances]
    n_rows = (len(instances) - 1) // images_per_row + 1
    row_images = []
    n_empty = n_rows * images_per_row - len(instances)
    images.append(np.zeros((size, size * n_empty)))
    for row in range(n_rows):
        rimages = images[row * images_per_row : (row + 1) * images_per_row]
        row_images.append(np.concatenate(rimages, axis=1))
    image = np.concatenate(row_images, axis=0)
    plt.imshow(image, cmap = mpl.cm.binary, **options)
    plt.axis("off")
```


```python
plt.figure(figsize=(9,9)) # 사이즈
example_images = X[:100] # 100개 데이터
plot_digits(example_images, images_per_row=10) # row 10개 나열
plt.show()
```


![png](https://user-images.githubusercontent.com/45762604/85260485-bbb49900-b4a5-11ea-9e00-cf290d07c489.png)



```python
# 훈련 데이터와 테스트 데이터 나누기
# 책에서 나와 있듯이 이미 랜덤으로 잘 섞여 있어서 슬라이싱 가능!!
# 랜덤으로 안 섞인 데이터는 그냥 슬라이싱으로 나우면 안됨!!
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]

```

## 이진 분류기 훈련
* 문제를 단순화해서 하나의 숫자 (여기서는 5)만 식별하기


* 5가 맞는지 (양성), 5가 아닌지 (음성)

  두 개의 클래스를 구분할 수 있는 이진 분류기이다


```python
# 훈련, 테스터 타겟 벡터 만들기 
y_train_5 = (y_train == 5) # 5는 True이고, 다른 숫자는 모두 False
y_test_5 = (y_test == 5)
```

사이킷런의 SGDClassifier class를 사용해 확률적 경사 하강법 분류기로 훈련시키기

확률적 경사 하강법 (SGD: Stochastic Gradient Descent) 분류기
-> 분류용 알고리즘

* 큰 데이터를 효율적으로 처리
* 한번에 하나씩 훈련 샘플을 독립적으로 처리함
* 여러개의 분류 모델 만들수 있음 -> 서포트 벡터머신, 로지스틱 회귀...


```python
from sklearn.linear_model import SGDClassifier

# 무작위성을 사용하기 때문에 random_state 매개변수를 지정해야 함!
sgd_clf = SGDClassifier(random_state=42)
 
sgd_clf.fit(X_train, y_train_5)
```




    SGDClassifier(random_state=42)




```python
#predict는 이차원 배열 가정하기때문에 ([some_digit]) 배열안에 넣어야함
sgd_clf.predict([some_digit])
```




    array([ True])



## 성능 측정
### 교차검증을 사용한 정확도 측정



```python
# 사이킷런은 교차 검증을 위해 cross_val_score 함수를 제공한다 

from sklearn.model_selection import cross_val_score
cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring="accuracy")
# scoring="accuracy" 분류모델의 기본
```




    array([0.95035, 0.96035, 0.9604 ])



k폴드 교차 검증

cross_val_score(모델명, 훈련 데이터, 데이터 타깃, cv,)

cv = 폴드수
* default = 3
* 3-겹 교차 검증
* 3개로 나눠서 훈련과 검증을 순차적으로 바꾸면서 검증


교차 검증 구현하기
* 사이킷런이 제공하는 기능보다 교차 검증 과정을 더 많이 제어해야할 때 직접 구현
* 아래의 함수는 사이킷런의 cross_val_score() 함수와 거의 같은 작업을 수행하고 동일한 결과를 출력


```python
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone


# shuffle=False가 기본값이기 때문에 random_state를 삭제하던지 shuffle=True로 지정하라는 경고가 발생합니다.
# 0.24버전부터는 에러가 발생할 예정이므로 향후 버전을 위해 shuffle=True을 지정합니다.

# StratifiedKFold는 class 별 비율이 유지되도록 폴드를 만들기 위해 계층적 샘플링을 수행함!
skfolds = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)

for train_index, test_index in skfolds.split(X_train, y_train_5):
    # 매 반복에서 분류기 객체를 복제하여
    clone_clf = clone(sgd_clf) 
    
    X_train_folds = X_train[train_index]  
    y_train_folds = y_train_5[train_index]
    
    X_test_fold = X_train[test_index]
    y_test_fold = y_train_5[test_index]
    
     # 훈련 폴드로 훈련시키고
    clone_clf.fit(X_train_folds, y_train_folds)
    
    # 테스트 폴드로 예측을 만든다
    y_pred = clone_clf.predict(X_test_fold)
    
    # 올바른 예측의 수를 세어
    n_correct = sum(y_pred == y_test_fold)
    
    # 정확한 예측의 비율을 출력!
    print(n_correct / len(y_pred))
    

```

    0.9669
    0.91625
    0.96785



```python
#위에는 함수와 같음

skfolds = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)

cross_val_score(sgd_clf, X_train, y_train_5, cv=skfolds)
```




    array([0.9669 , 0.91625, 0.96785])



모든 교차 검증 폴드에 대해 정확도 (정확한 예측의 비율) 이 95% 이상

모델 정확도 추측하기


```python
# BaseEstimator -> cross_val_score 사용할 경우 상속해야함
# 유용한 메소드를 만들어줌
from sklearn.base import BaseEstimator
class Never5Classifier(BaseEstimator):
    def fit(self, X, y=None):
        pass
    def predict(self, X):
        return np.zeros((len(X), 1), dtype=bool)

```


```python
# 5(양성)클래스 10% 에서 무조건 no 조건이면 90%이상 나옴
never_5_clf = Never5Classifier()
cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```




    array([0.91125, 0.90855, 0.90915])



정확도 90%이상 나옴

but! 숫자 5는 이미지 10%이기에 무조건 5아님으로 예측하면 확률이 90%임

그래서 이 예제는 정확도 하나만 가지고 모델이 좋다 나쁘다 말하기 힘듬


### 오차 행렬

분류기의 성능을 평가하는 더 좋은 방법은 오차 행렬을 조사하는 것

* Class A의 샘플이 Class B로 분류된 횟수를 센다.
* ex) 분류기가 숫자 5의 이미지를 3으로 잘못 분류한 횟수 == 오차 행렬의 5행 3열을 보면 확인 가능

오차 행렬 만들기
* 실제 타깃과 비교할 수 있도록 예측값 만들기 : 사이킷런의 cross_val_predict() 함수 사용


```python
from sklearn.model_selection import cross_val_predict
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)

```


```python
# confusion_matrix() 오차행렬 

from sklearn.metrics import confusion_matrix

confusion_matrix(y_train_5, y_train_pred)
                # 타깃 클래스, 예측 클래스 실행
```




    array([[53892,   687],
           [ 1891,  3530]])



분석 결과

행은 -> 실제 클래스

열은 -> 예측 클래스

* 첫번째 행 (데이터는 5개 아님)
    * 53892 개는 정확하게 5아님 분류 -> 진짜 음성
    * 687 개는 5라고 잘못 분류 -> 거짓 양성
* 두번째 행 (데이터는 5개 맞음)
    * 1891 개는 5아님으로 분류 -> 거짓 음성
    * 3530 개는 정확하게 5라고 분류 -> 진짜 양성
    

![png](https://user-images.githubusercontent.com/45762604/85261083-a5f3a380-b4a6-11ea-8b85-53b78b3e4f58.png)


Accuracy(정확도), Recall(재현율), Precision(정밀도)

양성 예측 정확도 -> 정밀도

정확하게 감지한 양성 샘플 비율 -> 재현율


* 정밀도 

    = 진짜 양성 수 / (진짜 양성 수 + 거짓 양성 수)

    = (3530) / (3530 + 687)

    = 5(양성)로 예측한 값의 비율(5로 잘못 판단된 수 포함)


* 재현율

    = 진짜 양성 수 / (진짜 양성수 + 거짓 음성 수)

    = (3530) / (3530 + 1891)

    = 모든 5의 값 비율(5가 맞지만 잘못 분류된 5포함)


### 정밀도와 재현율


```python
# 사이킷런은 정밀도와 재현율을 포함하여 분류기의 지표를 계산하는 여러 함수를 제공한다!

from sklearn.metrics import precision_score, recall_score

# 정밀도 
precision_score(y_train_5, y_train_pred)
```




    0.8370879772350012




```python
# 정밀도
# 진짜 양성 수 / (진짜 양성 수 + 거짓 양성 수)
3530 / (3530 + 687)
```




    0.8370879772350012




```python
# 재현율
recall_score(y_train_5, y_train_pred)
```




    0.6511713705958311




```python
# 재현율
# 진짜 양성 수 / (진짜 양성수 + 거짓 음성 수)
3530 / (3530 + 1891)
```




    0.6511713705958311



 성능이 좋지 않아 보이는 것 확인 가능
 
 

 F1 score

정밀도와 재현율을 F1 score -> 조합 평균값으로 하나의 수치로 만듬

F1 score == 조화 평균


```python
from sklearn.metrics import f1_score

f1_score(y_train_5, y_train_pred)
```




    0.7325171197343846




```python
3530 / (3530 + (687 + 1891) / 2)
```




    0.7325171197343847



정밀도와 재현율이 비슷한 분류기에서는 F1 점수가 높다
* but, 이게 항상 바람직한 것은 아님

안전한 것들만 노출시키는 높은 정밀도의 분류기, 

정확도는 낮아도 재현율이 높은 분류기 등 상황에 따라 따르다

하지만 정밀도와 재현율을 모두 얻을 수 는 없다

* 정밀도를 높이면 재현율이 줄고
* 재현율을 높이면 정밀도가 줄어든다

-> 이것을 정밀도/재현율 트레이드 오프 라고 한다!


```python

```

### 정밀도/재현율 트레이드오프



```python
# SGDClassifier의 decision_function()으로 양성, 음성 판단할수 있는 값  

y_scores = sgd_clf.decision_function([some_digit])
y_scores
```




    array([2164.22030239])




```python
threshold = 0  # SGDClassifier의 임계값이 0이므로 
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred # predict() method 와 같은 결과 (True) 를 반환!
```




    array([ True])




```python
threshold = 8000 # 임계값을 높이자,
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred # False 를 반환
```




    array([False])



위의 결과는 임계값을 높이면 재현율 이 줄어든다는 것을 보여준다!

임계값 정하기


```python
# Step 1
#: cross_val_predict() 함수를 사용해 훈련 세트에 있는 모든 샘플의 점수 구하기

y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,
                             method="decision_function")
# method="decision_function" 예측 결과가 아닌, 결정 함수를 반환 받도록 지정!
```


```python
# Step 2
# : 사이킷런의 precision_recall_curve() 
# 정밀도, 재현율, 임계값 계산해줌

from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)

```


```python
# Step 3
# : 맷플롯립을 이용해 임계값의 함수로 정밀도와 재현율을 그리기

def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):
    plt.plot(thresholds, precisions[:-1], "b--", label="Precision ", linewidth=2) # 정밀도
    plt.plot(thresholds, recalls[:-1], "g-", label="Recall", linewidth=2) # 재현율
    
    # 임계값을 표시하고 범례, 축 이름, 그리드 추가하기!
    plt.legend(loc="center right", fontsize=16) # Not shown in the book
    plt.xlabel("Threshold", fontsize=16)        # Not shown
    plt.grid(True)                              # Not shown
    plt.axis([-50000, 50000, 0, 1])             # Not shown



recall_90_precision = recalls[np.argmax(precisions >= 0.90)]
threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]


plt.figure(figsize=(8, 4))                                                                  # Not shown
plot_precision_recall_vs_threshold(precisions, recalls, thresholds)
plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], "r:")                 # Not shown
plt.plot([-50000, threshold_90_precision], [0.9, 0.9], "r:")                                # Not shown
plt.plot([-50000, threshold_90_precision], [recall_90_precision, recall_90_precision], "r:")# Not shown
plt.plot([threshold_90_precision], [0.9], "ro")                                             # Not shown
plt.plot([threshold_90_precision], [recall_90_precision], "ro")                             # Not shown                                            


plt.show()

# Precision(정밀도), Recall(재현율)
```


![png](https://user-images.githubusercontent.com/45762604/85260500-beaf8980-b4a5-11ea-9c20-4066863dc5d0.png)



```python
(y_train_pred == (y_scores > 0)).all()
```




    True



좋은 정밀도/재현율 트레이드오프를 선택하는 또 다른 방법

재현율에 대한 정밀도 곡선 그리기


```python
# 정밀도 재현율 곡선
def plot_precision_vs_recall(precisions, recalls):
    plt.plot(recalls, precisions, "b-", linewidth=2)
    plt.xlabel("Recall", fontsize=16)
    plt.ylabel("Precision", fontsize=16)
    plt.axis([0, 1, 0, 1])
    plt.grid(True)

plt.figure(figsize=(8, 6))
plot_precision_vs_recall(precisions, recalls)
plt.plot([0.4368, 0.4368], [0., 0.9], "r:")
plt.plot([0.0, 0.4368], [0.9, 0.9], "r:")
plt.plot([0.4368], [0.9], "ro")

plt.show()

# Precision(정밀도), Recall(재현율)
```


![png](https://user-images.githubusercontent.com/45762604/85260509-c2dba700-b4a5-11ea-9127-513c8b85912b.png)


 

* 재현율 80% 근처에서 정밀도가 급격하게 줄어들기 시작하는 것 확인 가능

* 이 하강점 직전을 정밀도/재현율 트레이드오프로 선택하는 것이 좋다!

* 그래프가 오른쪽 위로 붙을수도 좋으며, 면적이 넓으면 좋은 모델!!



![png](https://user-images.githubusercontent.com/45762604/85261178-c1f74500-b4a6-11ea-9ed9-daf706632ba7.png)



```python
# 그래프 모델 면적 구하기 -> 면적이 넓으면 좋은 모델
from sklearn.metrics import average_precision_score

average_precision_score(y_train_5,y_scores)

```




    0.810041762752646




```python
# ex) 최소한 90% 정밀도가 되는 가장 낮은 임계값 찾기

threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)] 
# argmax() 함수는 최댓값의 첫 번째 index를 반환한다!

threshold_90_precision
```




    3370.0194991439557




```python
#  90%(3370) 보다 큰 스코어만 True로 판단

y_train_pred_90 = (y_scores >= threshold_90_precision)

# 이 예측에 대한 정밀도

precision_score(y_train_5, y_train_pred_90)
```




    0.9000345901072293




```python
# 재현율은 많이 떨어짐..

recall_score(y_train_5, y_train_pred_90)
```




    0.4799852425751706



어떤 가상의 정밀도에 대해 분류기를 만들려면 충분히 큰 임계값을 지정하라!

단, 재현율이 너무 낮다면 높은 정밀도의 분류기는 (당연히) 전혀 유용하지 않음

### ROC 곡선


* 수신기 조작 특성 (ROC: Receiver Operating Characteristic) 도 이진 분류에서 널리 사용된다


* 정밀도/재현율 곡선과 매우 비슷하지만, 
* ROC 곡선은

    거짓 양성 비율 -FPR (5로 잘못 판단)에 대한 
    
    진짜 양성 비율 -TPR (5로 정확하게 판단) 
    
    == 재현율 의 곡선
    
ROC 곡선

== 모든 가능한 임계값에서 진짜 양성 비율에 대한 거짓 양성 비율을 나타낸다!

ROC 곡선 그리기

![png](https://user-images.githubusercontent.com/45762604/85275092-cd546b80-b4ba-11ea-8f11-d7a2dfe34073.png)

```python

```


```python
# roc_curve() 여러 임계값에서 TPR (재현율) 과 FPR (거짓 양성 비율) 계산

from sklearn.metrics import roc_curve

fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)
```


```python
# matplotlib을 사용해 재현율에 대한 거짓 양성 비율 곡선 나타내기

def plot_roc_curve(fpr, tpr, label=None):
    plt.plot(fpr, tpr, linewidth=2, label=label)
    plt.plot([0, 1], [0, 1], 'k--') # 대각 점선
    
    # 축 이름, 그리드 추가
    plt.axis([0, 1, 0, 1])                                    # Not shown in the book
    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) # Not shown
    plt.ylabel('True Positive Rate (Recall)', fontsize=16)    # Not shown
    plt.grid(True)                                            # Not shown

plt.figure(figsize=(8, 6))                         # Not shown
plot_roc_curve(fpr, tpr)
plt.plot([4.837e-3, 4.837e-3], [0., 0.4368], "r:") # Not shown
plt.plot([0.0, 4.837e-3], [0.4368, 0.4368], "r:")  # Not shown
plt.plot([4.837e-3], [0.4368], "ro")               # Not shown

plt.show()
```


![png](https://user-images.githubusercontent.com/45762604/85260518-c5d69780-b4a5-11ea-840b-2cf4e4895a00.png)


* 여기에도 트레이드오프가 있다!

    재현율 (TPR) 이 높을수록 분류기가 만드는 거짓 양성 (FPR) 이 늘어남
    
    
* 점선은 완전한 랜덤 분류기의 ROC 곡선을 뜻함

    * 왼쪽 위 모서리에 가까워야 좋은 모델
    * 면적이 넓어야 좋은 모델

랜덤 분류기란?
: 훈련 데이터의 클래스 비율에 따라 무작위로 예측하는 것

곡선 아래의 면적 (AUC: Area Under the Curve) 를 측정하여 분류기들을 비교하기


```python
# 곡선 아래의 면적
from sklearn.metrics import roc_auc_score

roc_auc_score(y_train_5, y_scores)


```




    0.9604938554008616




완벽한 분류기는 ROC의 AUC 가 1 이다

랜덤 분류기는 0.5

RandomForestClassifier와 SDGClassifier, ROC 곡선 비교


```python
from sklearn.ensemble import RandomForestClassifier
forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)
# n_estimators=100 -> 100개의 결정 트리 

y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,
                                    method="predict_proba") 
# method="predict_proba"는 예측의 확률값을 반환한다! -> roc 곡선에 넣을 스코어값

```


```python
# roc_curve(레이블, 점수) 이지만,

y_scores_forest = y_probas_forest[:, 1] 

#[음성, 양성] -> [:,1] ->양성클래스 확률

fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest) 
                                                    # 레이블        클래스 확률
```


```python
# ROC 곡선 그리기

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, "b:", linewidth=2, label="SGD")
plot_roc_curve(fpr_forest, tpr_forest, "Random Forest")
plt.plot([4.837e-3, 4.837e-3], [0., 0.4368], "r:")
plt.plot([0.0, 4.837e-3], [0.4368, 0.4368], "r:")
plt.plot([4.837e-3], [0.4368], "ro")
plt.plot([4.837e-3, 4.837e-3], [0., 0.9487], "r:")
plt.plot([4.837e-3], [0.9487], "ro")
plt.grid(True)
plt.legend(loc="lower right", fontsize=16)

plt.show()
```


![png](https://user-images.githubusercontent.com/45762604/85260522-c8d18800-b4a5-11ea-9453-779e8e31a9aa.png)


* 랜덤 포레스트의 분류기가 SGD 분류기보다 훨씬 좋다

* 랜덤 포레스트의 ROC 곡선이 왼쪽 위 모서리에 더 가까워 AUC 값이 크기 때문!



```python
# 랜덤 포레스트 분류기의 ROC AUC 점수도 더 높다

roc_auc_score(y_train_5, y_scores_forest)
```




    0.9983436731328145



* 랜덤 포레스트 분류기 - 0.9983436731328145
* SDG 분류기 - 0.9604938554008616  


```python
# 랜덤 포레스트 분류기의 정밀도

y_train_pred_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3)
precision_score(y_train_5, y_train_pred_forest)
```




    0.9905083315756169




```python
# 랜덤 포레스트 분류기의 재현율

recall_score(y_train_5, y_train_pred_forest)
```




    0.8662608374838591



-----------------------------
랜덤 포레스트, SDG 비교 

랜덤 포레스트
* 99.8% 의 AUC 점수
* 99.0% 의 정밀도
* 86.6% 의 재현율

SDG 
* 96.0% 의 AUC 점수
* 90.0% 의 정밀도
* 47.9% 의 재현율

## 다중분류

이진 분류가 두 개의 클래스를 구별하는 반면, 다중 분류기 (Multiclass classifier) 는 둘 이상의 클래스를 구별할 수 있다

* SDG 분류기, 랜덤 포레스트 분류기, 나이브 베이즈 분류기 같은 일부 알고리즘은 여러 개의 클래스 를 직접 처리 할 수 있는 방면,
* 로지스틱 회귀 나 서포트 벡터 머신 분류기 같은 알고리즘은 이진 분류 만 가능하다

but, 이진 분류기를 여러 개 사용해 다중 클래스를 분류하는 기법도 많다!

* 특정 숫자 하나만 구분하는 숫자별 이진 분류기 10개 (0~9) 를 훈련시켜 클래스가 10개인 숫자 이미지 분류 시스템 만들기

    * 이미지를 분류할 때 각 분류기의 결정 점수 중에서 가장 높은 것을 클래스로 선택    
    * OvR (One versus the Rest) 전략
        
        
* 0 과 1 구별, 0과 2 구별 등과 같이 각 숫자의 조합마다 이진 분류기를 훈련

    * OvO (One versus One) 전략
    * 장점: 각 분류기의 훈련에 전체 훈련 세트 중 구별할 두 클래스에 해당하는 샘플만 필요하다

다중 클래스 분류 작업에 이진 분류 알고리즘을 선택하면 사이킷런 이 알고리즘에 따라 자동으로 OvR 또는 OvO를 실행한다


```python
# 사이킷런의 SVC class를 사용해서 서포트 벡터 머신 분류기를 테스트 하기

from sklearn.svm import SVC

svm_clf = SVC(gamma="auto", random_state=42)

#SVC 를 훈련시키기
svm_clf.fit(X_train[:1000], y_train[:1000])#y_train_5아님 y_train을 사용
svm_clf.predict([some_digit]) #예측을 만듦
```




    array([5], dtype=uint8)



내부에서는 사이킷런이 OvO 전략을 사용해

* 10개의 이진 분류기를 훈련시키고,

* 각각의 결정 점수를 얻어

* 점수가 가장 높은 클래스를 선택함


```python
# 확인

some_digit_scores = svm_clf.decision_function([some_digit])
some_digit_scores
```




    array([[ 2.81585438,  7.09167958,  3.82972099,  0.79365551,  5.8885703 ,
             9.29718395,  1.79862509,  8.10392157, -0.228207  ,  4.83753243]])




```python
# 가장 높은 점수가 인덱스 5임을 확인 -> 9.29718395

np.argmax(some_digit_scores)
```




    5




```python
# 분류기가 훈련될 때 classes_ 속성에 타깃 클래스의 리스트를 값으로 정렬하여 저장하므로

svm_clf.classes_
```




    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)




```python
# 인덱스 5의 속성을 확인

svm_clf.classes_[5]
```




    5



인덱스 5의 속성이 5이므로 가장 높은 점수가 5임을 (정확히 예측했음) 확인 할 수 있다!

사이킷런에서 OvO나 OvR을 사용하도록 강제하려면 OneVsOneClassifier OneVsRestClassifier 를 사용한다


```python
from sklearn.multiclass import OneVsRestClassifier 

ovr_clf = OneVsRestClassifier(SVC(gamma="auto", random_state=42))
ovr_clf.fit(X_train[:1000], y_train[:1000])
ovr_clf.predict([some_digit])
```




    array([5], dtype=uint8)




```python
len(ovr_clf.estimators_)
```




    10




```python
sgd_clf.fit(X_train, y_train)
sgd_clf.predict([some_digit])
```




    array([3], dtype=uint8)




```python
sgd_clf.decision_function([some_digit])
```




    array([[-31893.03095419, -34419.69069632,  -9530.63950739,
              1823.73154031, -22320.14822878,  -1385.80478895,
            -26188.91070951, -16147.51323997,  -4604.35491274,
            -12050.767298  ]])




```python
# 정확도 평가  ...오래걸림
from sklearn.model_selection import cross_validate
cross_validate(sgd_clf, X_train, y_train, cv=3, scoring="accuracy") 
# cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring="accuracy")
```




    {'fit_time': array([74.954741  , 60.75974989, 56.69884992]),
     'score_time': array([0.03411484, 0.040452  , 0.02783704]),
     'test_score': array([0.87365, 0.85835, 0.8689 ])}




결과 -> cross_val_score -> array([0.87365, 0.85835, 0.8689 ])


```python
# 입력 스케일을 조정하여 정확도 다시 평가하기  ...굉장히 오래걸림

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))
cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring="accuracy")
```




    array([0.8983, 0.891 , 0.9018])



결과 -> array([0.8983, 0.891, 0.9018])

## 에러 분석

가능성이 높은 모델을 하나 찾았다고 가정하고, 모델의 성능을 향상시킬 방법 찾기

방법 1) 만들어진 에러의 종류 분석


```python
# 오차 행렬 살펴보기

# cross_val_predict() 함수를 사용해 예측을 만들고
y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)

# confusion_matrix() 함수 호출
conf_mx = confusion_matrix(y_train, y_train_pred)
conf_mx
```




    array([[5577,    0,   22,    5,    8,   43,   36,    6,  225,    1],
           [   0, 6400,   37,   24,    4,   44,    4,    7,  212,   10],
           [  27,   27, 5220,   92,   73,   27,   67,   36,  378,   11],
           [  22,   17,  117, 5227,    2,  203,   27,   40,  403,   73],
           [  12,   14,   41,    9, 5182,   12,   34,   27,  347,  164],
           [  27,   15,   30,  168,   53, 4444,   75,   14,  535,   60],
           [  30,   15,   42,    3,   44,   97, 5552,    3,  131,    1],
           [  21,   10,   51,   30,   49,   12,    3, 5684,  195,  210],
           [  17,   63,   48,   86,    3,  126,   25,   10, 5429,   44],
           [  25,   18,   30,   64,  118,   36,    1,  179,  371, 5107]])




```python
# 아래에서 결과를 보기 쉽게 하기 위해 색을 넣어주는 함수 만들기

def plot_confusion_matrix(matrix):
    """If you prefer color and a colorbar"""
    fig = plt.figure(figsize=(8,8))
    ax = fig.add_subplot(111)
    cax = ax.matshow(matrix)
    fig.colorbar(cax)
```


```python
# matplotlib의 matshow() 함수를 이용해 이미지로 보기

plt.matshow(conf_mx, cmap=plt.cm.gray)

plt.show()
```


![png](https://user-images.githubusercontent.com/45762604/85260529-cc650f00-b4a5-11ea-81b7-df607bccbc4e.png)


그래프의 에러 부분에 초점을 맞추기


```python
row_sums = conf_mx.sum(axis=1, keepdims=True) # 오차 행렬의 각 값을
norm_conf_mx = conf_mx / row_sums # 대응되는 클래스의 이미지 개수로 나누어 에러 비율을 비교한다

```

에러 비율을 비교하는 이유


: 에러의 절대 개수로 비교하면 이미지가 많은 클래스가 상대적으로 나쁘게 보이기 때문!


```python
# 다른 항목은 그대로 유지하고,

# 주 대각선만 0으로 채워서 
np.fill_diagonal(norm_conf_mx, 0) 

# 그래프 그리기
plt.matshow(norm_conf_mx, cmap=plt.cm.gray)

plt.show()
```


![png](https://user-images.githubusercontent.com/45762604/85260541-cff89600-b4a5-11ea-8844-dfa47e0da929.png)



행: 실제 클래스

열: 예측한 클래스


오차 행렬을 분석하면 분류기의 성능 향상 방안에 대한 통찰력을 얻을 수 있다
* 위의 그래프에서 8로 잘못 분류되는 것을 줄이도록 개선할 필요가 있음
* 예) 8처럼 보이는 숫자의 훈련 데이터를 더 많이 모아서 실제 8과 구분하도록 분류기를 학습시킬 수 있음
* 분류기에 도움이 될 만한 특성을 더 찾아볼 수 있음
* 예) 동심원의 수를 세는 알고리즘 (8은 2개, 6은 1개, 5는 0개 등)
* 동심원 같은 어떤 패턴이 드러나도록 이미지를 전처리 해볼 수 있음
* 이렇게 분석하며 통찰을 얻을 수 있지만, 더 어렵고 시간이 오래걸린다


```python
# 예) 3, 5의 샘플 그려보기

cl_a, cl_b = 3, 5
X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]
X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]
X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]
X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]

plt.figure(figsize=(8,8))
plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)
plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)
plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)
plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)

plt.show()
```


![png](https://user-images.githubusercontent.com/45762604/85260545-d424b380-b4a5-11ea-8df6-9130fef16d15.png)


* 왼쪽 5*5 블록 두 개는 3으로 분류된 이미지
* 오른쪽 5*5 블록 두 개는 5로 분류된 이미지

위의 결과를 통해 에러를 확인할 수 있음
* 원인
    선형 모델인 SDGClassifier 를 사용했기 때문
    
    선형 분류기는 클래스마다 픽셀에 가중치를 할당하고 새로운 이미지에 대해 단순히 픽셀 강도 의 가중치 합을 클래스의 점수로 계산
    따라서, 3과 5는 몇 개의 픽셀만 다르기 때문에 모델이 쉽게 혼동하게 됨!


* 해결 방법
    3과 5의 주요 차이
    
    위쪽 선과 아래쪽 호를 이어주는 작은 직선의 위치이므로
    이미지를 중앙에 위치시키고
    회전되어 있지 않도록 전처리하기

## 다중 레이블 분류
* 분류기가 샘플마다 여러개의 클래스를 출력해야 할 때
    * 여러개의 이진 꼬리표를 출력하는 분류 시스템을 다중 레이블 분류 시스템이라고 한다


```python
from sklearn.neighbors import KNeighborsClassifier

# 숫자가 큰 값 (7,8,9) 인지
y_train_large = (y_train >= 7)

# 홀 수 인지
y_train_odd = (y_train % 2 == 1)

# 두 개의 타깃 레이블이 담긴 y_multilabel 배열 만들기
y_multilabel = np.c_[y_train_large, y_train_odd]

# KNeightborsClassifier instance 를 만들고
knn_clf = KNeighborsClassifier()

# 다중 타깃 배열 (y_multilabel)을 사용하여 훈련시키기 
knn_clf.fit(X_train, y_multilabel)
```




    KNeighborsClassifier()




```python
knn_clf.predict([some_digit])
```




    array([[False,  True]])



위의 결과를 통해 올바르게 분류된 것을 확인 할 수 있다!

숫자 5는 큰 값이 아니고, 홀수이다


```python
# 다중 레이블 분류기를 평가하기

# 아래의 코드는 모든 레이블에 대한 F1 점수의 평균을 계산한다   .... 하지만 실행하지 않을 예정

# y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)
# f1_score(y_multilabel, y_train_knn_pred, average="macro") 
                                   # average="weighted" 로 바꾸어 타깃 레이블에 속한 샘플 수에 가중치를 줄 수 있다
                                    # -> 특정 레이블에 데이터가 많다면 해당 레이블에 대한 분류기의 점수에 더 높은 가중치를 두는 것!
        

```

결과 -> 0.97641026550605

## 다중 출력 분류
* 다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화 한 것


```python
# MNIST 이미지에서 추출한 훈련 세트와 테스트 세트에 넘파이의 randint() 함수를 사용하여
noise = np.random.randint(0, 100, (len(X_train), 784))

# 픽셀 강도에 잡음을 추가
X_train_mod = X_train + noise
noise = np.random.randint(0, 100, (len(X_test), 784))
X_test_mod = X_test + noise

# 타깃 이미지는 원본 이미지
y_train_mod = X_train
y_test_mod = X_test
```


```python
some_index = 0

# 잡음이 섞인 입력 이미지
plt.subplot(121); plot_digit(X_test_mod[some_index])

# 깨끗한 타깃 이미지
plt.subplot(122); plot_digit(y_test_mod[some_index])

plt.show()
```


![png](https://user-images.githubusercontent.com/45762604/85260568-da1a9480-b4a5-11ea-8ae6-8ee66f6e0e54.png)



```python
# 분류기를 훈련시켜 이 이미지를 깨끗하게 만들기

knn_clf.fit(X_train_mod, y_train_mod)
clean_digit = knn_clf.predict([X_test_mod[some_index]])
plot_digit(clean_digit)

```


![png](https://user-images.githubusercontent.com/45762604/85260579-ddae1b80-b4a5-11ea-881e-be313eeec147.png)



